---
description: 
globs: 
alwaysApply: false
---
# Rule: Generating Sub-Tasks from Main Tasks Analysis

## Goal

To guide an AI assistant in analyzing main tasks and breaking them down into detailed, implementable sub-tasks. Each sub-task must be specific, actionable, and small enough to be completed in a single development session while contributing to the completion of its parent main task.

## Process

1. **Read Main Tasks Document:** The AI must first read the main-tasks-[feature-name].md document to understand the atomic phases (tipically at `/docs/pre-development/tasks/`)
2. **Analyze Task Structure:** Extract and understand each main task's scope, dependencies, and deliverables
3. **Apply Granular Breakdown:** Ensure each sub-task is specific and implementable
4. **Generate Sub-Tasks:** Create detailed sub-task specifications using the structure below
5. **Save Output:** Create individual files for each main task and sub-task in `/docs/pre-development/tasks/` directory (see File Organization section)

## Input Document Analysis

### Main Tasks Analysis Requirements
- **Task Overview:** Extract the deliverable and atomic validation from each main task
- **Functional Scope:** Understand what features are included in each main task
- **Technical Scope:** Identify the technical components and architecture elements
- **Dependencies:** Map prerequisite tasks and blocking relationships
- **Acceptance Criteria:** Use acceptance criteria to guide sub-task creation

### Technical Context Requirements
- **PRD Reference:** Cross-reference with original PRD for detailed requirements
- **TRD Reference:** Leverage technical specifications for implementation details
- **Architecture Patterns:** Ensure sub-tasks align with defined architecture
- **Testing Strategy:** Include testing sub-tasks based on overall testing approach
- **Quality Standards:** Incorporate code quality and review requirements

## Sub-Task Principles

### Definition of "Implementable Sub-Task"
Each sub-task MUST be:
- **Single Session:** Can be completed in 2-4 hours maximum
- **Specific:** Has clear, unambiguous requirements
- **Testable:** Can be validated independently
- **Incremental:** Builds toward main task completion
- **Technical:** Includes specific implementation details

### Sub-Task Validation Checklist
Before finalizing each sub-task, ensure:
- [ ] **Clear Deliverable:** Specific code, config, or documentation output
- [ ] **Implementation Path:** Obvious how to implement the requirement
- [ ] **Test Strategy:** Clear how to validate the sub-task
- [ ] **Integration Point:** Clear how it fits with other sub-tasks
- [ ] **Definition of Done:** Unambiguous completion criteria

## Sub-Task Structure

Each generated sub-task should include these sections (strictly follow this structure):

### 1. Sub-Task Overview
- **Sub-Task ID:** ST-[main-task-id]-[number] (e.g., ST-MT-001-001, ST-MT-001-002)
- **Sub-Task Name:** Clear, action-oriented name (e.g., "Create Task Entity with Validation")
- **Parent Task:** Reference to main task (e.g., "MT-001: CLI Foundation with Local Storage")
- **Estimated Duration:** 2-4 hours maximum
- **Implementation Type:** Code, Configuration, Testing, Documentation, Research

### 2. Deliverable Specification
- **Primary Output:** Specific files, functions, or components to create
- **Code Location:** Exact file paths and directory structure
- **Technical Requirements:** Specific technologies, libraries, patterns to use
- **Interface Definition:** APIs, function signatures, data structures

### 3. Implementation Details
- **Step-by-Step Approach:** Numbered implementation steps
- **Code Examples:** Key code snippets or structure examples
- **Configuration Changes:** Specific config files or environment changes
- **Dependencies:** Libraries, packages, or tools needed

### 4. Acceptance Criteria
- **Functional Criteria:** What the code must do
- **Technical Criteria:** Code quality, performance, security requirements
- **Integration Criteria:** How it connects with existing components
- **Test Criteria:** Specific tests that must pass

### 5. Testing Requirements
- **Unit Tests:** Specific test cases to write
- **Integration Tests:** Integration points to test
- **Manual Testing:** Manual validation steps
- **Test Data:** Required test fixtures or data

### 6. Definition of Done
- **Code Complete:** All code written and reviewed
- **Tests Passing:** All tests written and passing
- **Documentation Updated:** Relevant docs updated
- **Integration Verified:** Works with existing components
- **Review Approved:** Code review completed

### 7. Dependencies and Blockers
- **Required Sub-Tasks:** Sub-tasks that must be completed first
- **External Dependencies:** Third-party services, libraries, or tools
- **Environmental Requirements:** Development environment setup needs
- **Potential Blockers:** Known issues or complications

### 8. Integration Notes
- **Component Interfaces:** How this integrates with other components
- **Data Flow:** How data moves through this component
- **Error Handling:** How errors are managed and propagated
- **Configuration Impact:** Environment or config changes needed

## Example Sub-Task Format

```markdown
## ST-MT-001-001: Create Task Entity with Validation

### 1. Sub-Task Overview
- **Sub-Task ID:** ST-MT-001-001
- **Sub-Task Name:** Create Task Entity with Validation
- **Parent Task:** MT-001: CLI Foundation with Local Storage
- **Estimated Duration:** 3 hours
- **Implementation Type:** Code

### 2. Deliverable Specification
- **Primary Output:** Task entity struct with validation methods
- **Code Location:** `cli/internal/domain/entities/task.go`
- **Technical Requirements:** Go structs with validation tags, error handling
- **Interface Definition:** Task struct with Create, Update, Validate methods

### 3. Implementation Details
- **Step-by-Step Approach:**
  1. Create `cli/internal/domain/entities/` directory
  2. Define Task struct with all required fields
  3. Add validation tags using go-playground/validator
  4. Implement validation methods
  5. Add custom validation for business rules
  6. Create constructor function with validation
  7. Add error handling for validation failures

- **Code Examples:**
  ```go
  type Task struct {
      ID          string    `json:"id" validate:"required,uuid"`
      Content     string    `json:"content" validate:"required,min=1,max=1000"`
      Status      Status    `json:"status" validate:"required,oneof=pending in_progress completed cancelled"`
      Priority    Priority  `json:"priority" validate:"required,oneof=low medium high"`
      Repository  string    `json:"repository" validate:"required"`
      CreatedAt   time.Time `json:"created_at"`
      UpdatedAt   time.Time `json:"updated_at"`
  }
  
  func NewTask(content, repository string) (*Task, error) {
      // Implementation with validation
  }
  ```

- **Configuration Changes:** None required
- **Dependencies:** 
  - `github.com/go-playground/validator/v10`
  - `github.com/google/uuid`

### 4. Acceptance Criteria
- **Functional Criteria:**
  - Task struct contains all required fields from PRD
  - Validation prevents invalid tasks from being created
  - Constructor function enforces business rules
  
- **Technical Criteria:**
  - Code follows Go conventions and project style
  - All public methods have documentation
  - Error messages are user-friendly
  
- **Integration Criteria:**
  - Can be imported by other domain services
  - JSON serialization works correctly
  
- **Test Criteria:**
  - All validation scenarios covered by tests
  - Constructor edge cases tested

### 5. Testing Requirements
- **Unit Tests:**
  - Valid task creation succeeds
  - Invalid content (empty, too long) fails validation
  - Invalid status/priority values fail validation
  - Invalid repository format fails validation
  - Constructor generates correct timestamps

- **Integration Tests:** None required (domain entity)
- **Manual Testing:** Verify JSON serialization in CLI output
- **Test Data:** Create test fixtures for valid/invalid task data

### 6. Definition of Done
- **Code Complete:** Task entity fully implemented with validation
- **Tests Passing:** All unit tests written and passing (‚â•90% coverage)
- **Documentation Updated:** Godoc comments on all public methods
- **Integration Verified:** Can be used by TaskService
- **Review Approved:** Code review completed by team lead

### 7. Dependencies and Blockers
- **Required Sub-Tasks:** None (foundational task)
- **External Dependencies:** Go validation library
- **Environmental Requirements:** Go 1.23+ development environment
- **Potential Blockers:** Validation library compatibility issues

### 8. Integration Notes
- **Component Interfaces:** Used by TaskService in domain layer
- **Data Flow:** Created from CLI input, stored via Storage interface
- **Error Handling:** Returns structured validation errors
- **Configuration Impact:** None
```

## Quality Standards

### Granularity Validation
Each sub-task must:
- [ ] **Single Purpose:** Addresses one specific implementation concern
- [ ] **Time-Bounded:** Can be completed in one development session
- [ ] **Clear Output:** Produces identifiable deliverable
- [ ] **Testable Scope:** Can be validated independently
- [ ] **Integration Ready:** Fits cleanly with other sub-tasks

### Implementation Readiness
Verify each sub-task:
- [ ] **Technical Clarity:** No ambiguity about what to implement
- [ ] **Architecture Alignment:** Follows established patterns
- [ ] **Dependency Management:** Clear prerequisite relationships
- [ ] **Test Coverage:** Testing approach clearly defined
- [ ] **Error Handling:** Error scenarios considered

## Output Structure

### File Organization

**IMPORTANT: Each main task and sub-task must be saved in separate files for simplified management.**

```
docs/pre-development/tasks/
‚îú‚îÄ‚îÄ main-tasks-[feature-name].md                    # Input document (overview)
‚îú‚îÄ‚îÄ MT-[id]/                                        # Directory per main task
‚îÇ   ‚îú‚îÄ‚îÄ main-task.md                               # Main task specification
‚îÇ   ‚îú‚îÄ‚îÄ ST-MT-[id]-[num].md                        # Individual sub-task files
‚îÇ   ‚îú‚îÄ‚îÄ ST-MT-[id]-[num].md
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ task-dependencies.md                            # Cross-task dependency mapping
‚îú‚îÄ‚îÄ implementation-checklist.md                     # Overall progress tracking
‚îî‚îÄ‚îÄ task-index.md                                  # Index of all tasks and sub-tasks
```

**File Naming Convention:**
- Main Tasks: `docs/pre-development/tasks/MT-[id]/main-task.md` (e.g., `MT-001/main-task.md`)
- Sub-Tasks: `docs/pre-development/tasks/MT-[id]/ST-MT-[id]-[num].md` (e.g., `MT-001/ST-MT-001-001.md`)
- Dependencies: `docs/pre-development/tasks/task-dependencies.md`
- Index: `docs/pre-development/tasks/task-index.md`

**Benefits of Individual Files:**
- **Simplified Management:** Each task can be tracked, assigned, and updated independently
- **Version Control:** Clean git history with granular changes per task
- **Parallel Development:** Multiple developers can work on different sub-tasks simultaneously
- **Progress Tracking:** Individual file status reflects completion state
- **Code Review:** Focused reviews per sub-task rather than large documents

### Task Index File Structure

Create `docs/pre-development/tasks/task-index.md` to maintain an overview of all tasks:

```markdown
# Task Index - [Feature Name]

## Main Tasks Overview

| Task ID | Status | Name | Sub-Tasks | Estimated Total |
|---------|--------|------|-----------|-----------------|
| MT-001 | In Progress | CLI Foundation | 5 | 16 hours |
| MT-002 | Pending | PRD Processing | 6 | 20 hours |
| MT-003 | Pending | Server Integration | 4 | 14 hours |

## Sub-Tasks by Main Task

### MT-001: CLI Foundation
- [x] [ST-MT-001-001](mdc:MT-001/ST-MT-001-001.md): Task Entity (3h) - ‚úÖ Complete
- [ ] [ST-MT-001-002](mdc:MT-001/ST-MT-001-002.md): Task Service (4h) - üîÑ In Progress
- [ ] [ST-MT-001-003](mdc:MT-001/ST-MT-001-003.md): Local Storage (3h) - ‚è≥ Pending
- [ ] [ST-MT-001-004](mdc:MT-001/ST-MT-001-004.md): CLI Commands (4h) - ‚è≥ Pending
- [ ] [ST-MT-001-005](mdc:MT-001/ST-MT-001-005.md): Integration Tests (2h) - ‚è≥ Pending

**Progress:** 1/5 Complete (20%)
```

**Status Icons:**
- ‚úÖ Complete
- üîÑ In Progress
- ‚è≥ Pending
- ‚ùå Blocked
- üö´ Cancelled

### Dependencies Visualization
Include a mermaid diagram showing sub-task dependencies:
```mermaid
graph TD
    A[ST-MT-001-001: Task Entity] --> B[ST-MT-001-002: Task Service]
    A --> C[ST-MT-001-003: Local Storage]
    B --> D[ST-MT-001-004: CLI Commands]
    C --> D
    D --> E[ST-MT-001-005: Integration Tests]
```

### Implementation Sequence
Provide recommended implementation order:
```
Week 1:
- ST-MT-001-001: Task Entity (Day 1)
- ST-MT-001-002: Task Service (Day 2)
- ST-MT-001-003: Local Storage (Day 3)

Week 2:
- ST-MT-001-004: CLI Commands (Day 1-2)
- ST-MT-001-005: Integration Tests (Day 3)
```

## Integration with Development Chain

### Input Sources
- **Main Tasks Document:** Primary source for sub-task breakdown
- **PRD Requirements:** Detailed functional requirements
- **TRD Specifications:** Technical implementation guidance
- **Architecture Patterns:** Structural requirements and constraints

### Output Usage
- **Sprint Planning:** Individual sub-task files become sprint items
- **Developer Assignment:** Sub-tasks can be assigned by file to individual developers
- **Progress Tracking:** File completion status indicates main task progress
- **Code Review:** Individual sub-task files provide focused review scope
- **Project Management:** Task files can be linked to issues, PRs, and project boards

## Validation Checklist

Before finalizing sub-tasks:
- [ ] **Main Task Coverage:** All main task requirements addressed
- [ ] **Dependency Logic:** Sub-task dependencies are logical and minimal
- [ ] **Implementation Clarity:** Each sub-task is unambiguous
- [ ] **Test Strategy:** Testing approach is comprehensive
- [ ] **Integration Points:** Clear how sub-tasks connect
- [ ] **Time Estimates:** Realistic 2-4 hour estimates
- [ ] **Definition of Done:** Clear completion criteria
- [ ] **Quality Standards:** Code quality requirements defined

## Sub-Task Categories

### Code Implementation Sub-Tasks
- Entity/model creation
- Service implementation
- API endpoint development
- Integration layer coding
- Utility function development

### Configuration Sub-Tasks
- Environment setup
- Build system configuration
- Dependency management
- Deployment configuration
- Security configuration

### Testing Sub-Tasks
- Unit test implementation
- Integration test creation
- End-to-end test development
- Performance test setup
- Security test implementation

### Documentation Sub-Tasks
- API documentation
- Code documentation
- User guide updates
- Architecture documentation
- Setup instructions

### Research Sub-Tasks
- Technology evaluation
- Library comparison
- Pattern research
- Performance analysis
- Security assessment

## Final Instructions

1. **Analyze Thoroughly:** Read main tasks document completely before starting
2. **Think Granularly:** Break down into implementable chunks
3. **Be Specific:** Provide concrete implementation guidance
4. **Consider Dependencies:** Map sub-task relationships carefully
5. **Include Testing:** Every code sub-task needs testing sub-tasks
6. **Define Completion:** Clear definition of done for each sub-task
7. **Estimate Realistically:** 2-4 hours per sub-task maximum
8. **Create Individual Files:** Save each main task and sub-task in separate files
9. **Update Index:** Maintain task-index.md with links to all task files
10. **Next Step:** After completing sub-tasks, teams can begin sprint planning and implementation

## Relationship to Chain

This rule completes the development chain:
1. **create-prd.mdc** ‚Üí Defines business requirements and high-level phases
2. **create-trd.mdc** ‚Üí Translates to technical specifications and implementation roadmap  
3. **generate-main-tasks.mdc** ‚Üí Creates atomic, functional development phases
4. **generate-sub-tasks.mdc** ‚Üí Breaks down each main task into implementable sub-tasks ‚Üê **YOU ARE HERE**

The output of this rule provides the final level of detail needed for development teams to begin implementation, with each sub-task representing a concrete, actionable work item that contributes to completing the overall system defined in the PRD.